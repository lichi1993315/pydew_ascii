#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èŠå¤©AIç³»ç»Ÿ - ä½¿ç”¨Claude APIä¸ºNPCç”Ÿæˆæ™ºèƒ½å›å¤
"""

import os
import json
import asyncio
import httpx
from typing import Dict, Optional, List
from datetime import datetime
from .ai_config_manager import get_config_manager

# å°è¯•å¯¼å…¥ç›¸å…³åº“
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False
    print("âš ï¸  anthropicåº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå›å¤æ¨¡å¼")

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸  openaiåº“æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨Doubaoæ¨¡å‹")

class ChatAI:
    """
    èŠå¤©AIç³»ç»Ÿ - ç®¡ç†NPCçš„æ™ºèƒ½å›å¤
    æ”¯æŒå¤šç§AIæ¨¡å‹ï¼šClaudeã€Doubao
    """
    
    def __init__(self, model_type: str = None):
        # åŠ è½½é…ç½®ç®¡ç†å™¨
        self.config_manager = get_config_manager()
        
        # æ¨¡å‹é…ç½®
        self.model_type = model_type or os.environ.get("AI_MODEL_TYPE") or self.config_manager.get_default_model()
        
        # APIé…ç½®
        self.claude_api_key = os.environ.get("CLAUDE_API_KEY")
        self.doubao_api_key = os.environ.get("ARK_API_KEY")
        
        # å®¢æˆ·ç«¯åˆå§‹åŒ–
        self.claude_client = None
        self.doubao_client = None
        self.current_client = None
        self.use_api = False
        
        # å“åº”ç¼“å­˜
        self.response_cache = {}  # ç¼“å­˜å›å¤ä»¥å‡å°‘APIè°ƒç”¨
        
        # å¯¹è¯å†å²ç®¡ç†
        self.conversation_history = {}  # æŒ‰NPC IDå­˜å‚¨å¯¹è¯å†å²
        chat_settings = self.config_manager.get_chat_settings()
        self.max_history_length = chat_settings.get("conversation_history_length", 10)   # æœ€å¤§ä¿å­˜çš„å¯¹è¯è½®æ•°
        
        # NPCè§’è‰²è®¾å®š
        self.npc_personalities = {
            "trader_zhang": {
                "name": "å•†äººå¼ ä¸‰",
                "personality": "ç²¾æ˜çš„å•†äººï¼Œè¯´è¯ç›´æ¥ï¼Œå–œæ¬¢è®¨è®ºç”Ÿæ„å’Œäº¤æ˜“",
                "context": "ç»è¥ç€å°é•‡çš„æ‚è´§åº—ï¼Œå‡ºå”®ç§å­å’Œè´­ä¹°å†œäº§å“",
                "speaking_style": "å•†äººå£å»ï¼Œçˆ±è°ˆé’±å’Œç”Ÿæ„"
            },
            "fisherman_li": {
                "name": "æ¸”å¤«è€æ",
                "personality": "ç»éªŒä¸°å¯Œçš„è€æ¸”å¤«ï¼Œè¯ä¸å¤šä½†å¾ˆå®åœ¨ï¼Œå¯¹é’“é±¼å¾ˆæœ‰å¿ƒå¾—",
                "context": "åœ¨å°é•‡æ± å¡˜è¾¹é’“é±¼çš„è€äººï¼ŒçŸ¥é“æ‰€æœ‰é’“é±¼æŠ€å·§",
                "speaking_style": "ç®€æœ´çš„è¯è¯­ï¼Œç»å¸¸åˆ†äº«é’“é±¼ç»éªŒ"
            },
            "farmer_wang": {
                "name": "å†œå¤«è€ç‹",
                "personality": "å‹¤åŠ³æœ´å®çš„å†œå¤«ï¼Œçƒ­çˆ±åœŸåœ°ï¼Œå¯¹å†œä¸šå¾ˆæœ‰ç»éªŒ",
                "context": "å°é•‡çš„å†œä¸šä¸“å®¶ï¼Œç§æ¤å„ç§ä½œç‰©",
                "speaking_style": "æœ´å®çš„å†œæ°‘è¯è¯­ï¼Œå–œæ¬¢è°ˆè®ºå†œä½œç‰©å’Œå¤©æ°”"
            },
            # çŒ«å’ªNPCè®¾å®š
            "cat_01": {
                "name": "å°æ©˜",
                "personality": "æ´»æ³¼å¥½åŠ¨çš„æ©˜çŒ«ï¼Œå–œæ¬¢åˆ°å¤„è·‘è·³ï¼Œå……æ»¡æ´»åŠ›",
                "context": "åœ¨å°é•‡è‡ªç”±æ¼«æ­¥çš„å¯çˆ±æ©˜çŒ«",
                "speaking_style": "æ´»æ³¼å¯çˆ±çš„çŒ«è¯­ï¼Œç»å¸¸ç”¨'å–µ'å¼€å¤´"
            },
            "cat_02": {
                "name": "å°ç™½",
                "personality": "æ¸©é¡ºå®‰é™çš„ç™½çŒ«ï¼Œå–œæ¬¢æ™’å¤ªé˜³ï¼Œæ€§æ ¼æ¸©å’Œ",
                "context": "ä¼˜é›…çš„ç™½çŒ«ï¼Œå–œæ¬¢å®‰é™çš„åœ°æ–¹",
                "speaking_style": "æ¸©æŸ”ä¼˜é›…çš„çŒ«è¯­ï¼Œè¯­æ°”è½»æŸ”"
            },
            "cat_03": {
                "name": "å°é»‘",
                "personality": "å¥½å¥‡å¿ƒå¼ºçš„é»‘çŒ«ï¼Œå–œæ¬¢æ¢ç´¢æ–°äº‹ç‰©",
                "context": "ç¥ç§˜çš„é»‘çŒ«ï¼Œæ€»æ˜¯åœ¨æ¢ç´¢æ–°çš„åœ°æ–¹",
                "speaking_style": "å¥½å¥‡çš„çŒ«è¯­ï¼Œç»å¸¸é—®é—®é¢˜"
            },
            "cat_04": {
                "name": "å°ç°",
                "personality": "æ…µæ‡’å¯çˆ±çš„ç°çŒ«ï¼Œæ€»æ˜¯æƒ³ç¡è§‰",
                "context": "æ‡’æ´‹æ´‹çš„ç°çŒ«ï¼Œå¤§éƒ¨åˆ†æ—¶é—´åœ¨ä¼‘æ¯",
                "speaking_style": "æ…µæ‡’çš„çŒ«è¯­ï¼Œç»å¸¸æ‰“å“ˆæ¬ "
            },
            "cat_05": {
                "name": "å°èŠ±",
                "personality": "èªæ˜æœºçµçš„èŠ±çŒ«ï¼Œä¼šå„ç§å°æŠŠæˆ",
                "context": "èªæ˜çš„èŠ±çŒ«ï¼Œå–œæ¬¢å±•ç¤ºè‡ªå·±çš„æŠ€èƒ½",
                "speaking_style": "èªæ˜çš„çŒ«è¯­ï¼Œå–œæ¬¢ç‚«è€€è‡ªå·±"
            },
            "cat_06": {
                "name": "å’ªå’ª",
                "personality": "ç²˜äººæ’’å¨‡çš„çŒ«å’ªï¼Œå–œæ¬¢è¢«æ‘¸æ‘¸",
                "context": "éå¸¸äº²äººçš„çŒ«å’ªï¼Œå–œæ¬¢ä¸äººç±»äº’åŠ¨",
                "speaking_style": "æ’’å¨‡çš„çŒ«è¯­ï¼Œç»å¸¸æ±‚æŠšæ‘¸"
            },
            "cat_07": {
                "name": "å–µå–µ",
                "personality": "ç‹¬ç«‹è‡ªä¸»çš„çŒ«ï¼Œæœ‰è‡ªå·±çš„æƒ³æ³•",
                "context": "ç‹¬ç«‹çš„çŒ«å’ªï¼Œæœ‰è‡ªå·±çš„ç”Ÿæ´»æ–¹å¼",
                "speaking_style": "ç‹¬ç«‹çš„çŒ«è¯­ï¼Œä¸å¤ªä¾èµ–ä»–äºº"
            },
            "cat_08": {
                "name": "çƒçƒ",
                "personality": "è´ªåƒçš„å°çŒ«ï¼Œå¯¹é£Ÿç‰©å¾ˆæ•æ„Ÿ",
                "context": "æ€»æ˜¯åœ¨å¯»æ‰¾é£Ÿç‰©çš„åœ†æ»šæ»šçŒ«å’ª",
                "speaking_style": "è´ªåƒçš„çŒ«è¯­ï¼Œç»å¸¸æåˆ°é£Ÿç‰©"
            },
            "cat_09": {
                "name": "æ¯›æ¯›",
                "personality": "èƒ†å°å®³ç¾çš„çŒ«ï¼Œå®¹æ˜“å—åˆ°æƒŠå“",
                "context": "å®³ç¾çš„é•¿æ¯›çŒ«ï¼Œä¸å¤ªæ•¢æ¥è¿‘é™Œç”Ÿäºº",
                "speaking_style": "èƒ†æ€¯çš„çŒ«è¯­ï¼Œè¯´è¯å°å¿ƒç¿¼ç¿¼"
            },
            "cat_10": {
                "name": "ç³–ç³–",
                "personality": "æ·˜æ°”æ£è›‹çš„çŒ«ï¼Œå–œæ¬¢æ¶ä½œå‰§",
                "context": "è°ƒçš®çš„çŒ«å’ªï¼Œæ€»æ˜¯åˆ¶é€ å°éº»çƒ¦",
                "speaking_style": "è°ƒçš®çš„çŒ«è¯­ï¼Œå……æ»¡æ¶ä½œå‰§ç²¾ç¥"
            }
        }
        
        # æ¨¡æ‹Ÿå›å¤æ¨¡æ¿
        self.mock_responses = {
            "trader_zhang": [
                "ä½ å¥½ï¼éœ€è¦ä¹°ç‚¹ä»€ä¹ˆå—ï¼Ÿæˆ‘è¿™é‡Œæœ‰æœ€æ–°é²œçš„ç§å­ï¼",
                "ç”Ÿæ„å…´éš†ï¼ä½ å¸¦äº†ä»€ä¹ˆå¥½è´§æ¥å–å—ï¼Ÿ",
                "å“å‘€ï¼Œè¿™ä½æœ‹å‹çœ‹èµ·æ¥å°±åƒä¸ªæˆåŠŸçš„å†œå¤«ï¼",
                "ä»·æ ¼å…¬é“ï¼Œç«¥åŸæ— æ¬ºï¼æƒ³è¦ä»€ä¹ˆå°½ç®¡è¯´ï¼"
            ],
            "fisherman_li": [
                "å°ä¼™å­ï¼Œé’“é±¼è¦æœ‰è€å¿ƒå•Š...",
                "ä»Šå¤©çš„é±¼å„¿ç‰¹åˆ«æ´»è·ƒï¼Œæ˜¯ä¸ªé’“é±¼çš„å¥½æ—¥å­ã€‚",
                "æˆ‘é’“äº†ä¸€è¾ˆå­é±¼ï¼Œæœ‰ä»€ä¹ˆä¸æ‡‚çš„å¯ä»¥é—®æˆ‘ã€‚",
                "é™ä¸‹å¿ƒæ¥ï¼Œé±¼å„¿è‡ªç„¶ä¼šä¸Šé’©çš„ã€‚"
            ],
            "farmer_wang": [
                "ç§åœ°ä¸å®¹æ˜“å•Šï¼Œè¦ç”¨å¿ƒç…§æ–™æ¯ä¸€æ ªä½œç‰©ã€‚",
                "çœ‹è¿™å¤©æ°”ï¼Œæ˜å¤©åº”è¯¥ä¼šä¸‹é›¨ï¼Œå¯¹åº„ç¨¼æœ‰å¥½å¤„ã€‚",
                "åœŸåœ°æ˜¯æˆ‘ä»¬çš„æ ¹æœ¬ï¼Œè¦å¥½å¥½çˆ±æŠ¤å¥¹ã€‚",
                "å¹´è½»äººï¼Œå†œä¸šå¯æ˜¯é—¨å¤§å­¦é—®ï¼"
            ],
            # çŒ«å’ªå›å¤
            "cat_01": [
                "å–µï¼ä½ å¥½å‘€ï¼Œæˆ‘æ˜¯å°æ©˜ï¼",
                "å–µå–µï½æƒ³å’Œæˆ‘ä¸€èµ·ç©å—ï¼Ÿ",
                "æ©˜çŒ«æœ€å¯çˆ±äº†ï¼Œå–µï¼",
                "è·‘è·‘è·³è·³çœŸå¼€å¿ƒï¼Œå–µï½"
            ],
            "cat_02": [
                "å–µ...ä½ å¥½ï¼Œæˆ‘æ˜¯å°ç™½...",
                "ä»Šå¤©çš„é˜³å…‰çœŸæ¸©æš–å‘¢ï¼Œå–µ...",
                "å®‰å®‰é™é™æœ€èˆ’æœäº†ï¼Œå–µï½",
                "è½»è½»çš„æ‘¸æ‘¸å¤´å°±å¥½ï¼Œå–µ..."
            ],
            "cat_03": [
                "å–µï¼Ÿä½ æ˜¯è°ï¼Ÿå¥½å¥‡æ€ªçš„äººç±»...",
                "è¿™é‡Œæœ‰ä»€ä¹ˆå¥½ç©çš„å—ï¼Œå–µï¼Ÿ",
                "æˆ‘è¦å»æ¢ç´¢æ–°åœ°æ–¹äº†ï¼Œå–µï¼",
                "é»‘çŒ«ä¹Ÿå¾ˆå¯çˆ±çš„ï¼Œå–µï½"
            ],
            "cat_04": [
                "å–µ...å¥½å›°å•Š...å“ˆæ¬ ï½",
                "è®©æˆ‘å†ç¡ä¸€ä¼šå„¿å˜›ï¼Œå–µ...",
                "æ‡’æ‡’çš„æœ€èˆ’æœäº†ï¼Œå–µï½",
                "ä¸æƒ³åŠ¨...åªæƒ³ç¡è§‰ï¼Œå–µ..."
            ],
            "cat_05": [
                "å–µï¼çœ‹æˆ‘çš„æ–°æŠŠæˆï¼",
                "æˆ‘å¾ˆèªæ˜çš„ï¼Œä»€ä¹ˆéƒ½ä¼šï¼Œå–µï½",
                "èŠ±çŒ«å°±æ˜¯æ¯”åˆ«çš„çŒ«å‰å®³ï¼Œå–µï¼",
                "è¦ä¸è¦çœ‹æˆ‘ç¿»è·Ÿå¤´ï¼Œå–µï¼Ÿ"
            ],
            "cat_06": [
                "å–µï½æ‘¸æ‘¸æˆ‘å˜›ï½",
                "æˆ‘æœ€å–œæ¬¢äººç±»äº†ï¼Œå–µï¼",
                "æŠ±æŠ±æˆ‘å¥½ä¸å¥½ï¼Œå–µï½",
                "å’ªå’ªè¦è¢«å® çˆ±ï¼Œå–µï¼"
            ],
            "cat_07": [
                "å–µ...æˆ‘æœ‰è‡ªå·±çš„äº‹è¦åš...",
                "ç‹¬ç«‹çš„çŒ«ä¸éœ€è¦åˆ«äººç…§é¡¾ï¼Œå–µã€‚",
                "æˆ‘æŒ‰è‡ªå·±çš„æ–¹å¼ç”Ÿæ´»ï¼Œå–µï½",
                "åˆ«å¤ªç²˜äººï¼Œä¿æŒè·ç¦»æ¯”è¾ƒå¥½ï¼Œå–µã€‚"
            ],
            "cat_08": [
                "å–µï¼ä½ æœ‰é£Ÿç‰©å—ï¼Ÿ",
                "è‚šå­å¥½é¥¿å•Šï¼Œæœ‰å°é±¼å¹²å—ï¼Œå–µï¼Ÿ",
                "çƒçƒè¦åƒå¥½åƒçš„ï¼Œå–µï½",
                "é—»åˆ°é¦™å‘³äº†ï¼Œåœ¨å“ªé‡Œå‘¢ï¼Œå–µï¼Ÿ"
            ],
            "cat_09": [
                "å–µ...ä¸è¦é å¤ªè¿‘...",
                "æˆ‘æœ‰ç‚¹å®³æ€•é™Œç”Ÿäººï¼Œå–µ...",
                "è¯·æ¸©æŸ”ä¸€ç‚¹å¥½å—ï¼Œå–µ...",
                "æ¯›æ¯›å¾ˆèƒ†å°çš„ï¼Œå–µ..."
            ],
            "cat_10": [
                "å–µå˜¿å˜¿ï¼è¦ä¸è¦çœ‹æˆ‘æ¶ä½œå‰§ï¼Ÿ",
                "ç³–ç³–æœ€ä¼šæ£è›‹äº†ï¼Œå–µï¼",
                "ä»Šå¤©åˆæäº†ä»€ä¹ˆåäº‹å‘¢ï¼Œå–µï½",
                "è°ƒçš®æ‰æœ‰è¶£ï¼Œä½ è¯´å¯¹å§ï¼Œå–µï¼Ÿ"
            ]
        }
        
        self._initialize_clients()
        self._set_active_model(self.model_type)
    
    def _initialize_clients(self):
        """åˆå§‹åŒ–æ‰€æœ‰å¯ç”¨çš„AIå®¢æˆ·ç«¯"""
        # åˆå§‹åŒ–Claudeå®¢æˆ·ç«¯
        if ANTHROPIC_AVAILABLE and self.claude_api_key:
            try:
                # ä½¿ç”¨ä¸test_claude_api.pyç›¸åŒçš„proxyè®¾ç½®
                custom_httpx_client = httpx.Client(
                    transport=httpx.HTTPTransport(
                        proxy=httpx.Proxy(
                            url="http://127.0.0.1:7890"
                        )
                    ),
                    timeout=30.0
                )
                
                self.claude_client = anthropic.Anthropic(
                    api_key=self.claude_api_key,
                    http_client=custom_httpx_client
                )
                print("ğŸ¤– ChatAI: Claude APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
                
            except Exception as e:
                print(f"ğŸ¤– ChatAI: Claude APIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆå§‹åŒ–Doubaoå®¢æˆ·ç«¯
        if OPENAI_AVAILABLE and self.doubao_api_key:
            try:
                self.doubao_client = openai.OpenAI(
                    api_key=self.doubao_api_key,
                    base_url="https://ark.cn-beijing.volces.com/api/v3",
                    timeout=30.0
                )
                print("ğŸ¤– ChatAI: Doubao APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
                
            except Exception as e:
                print(f"ğŸ¤– ChatAI: Doubao APIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        
        if not self.claude_client and not self.doubao_client:
            print("ğŸ¤– ChatAI: æ²¡æœ‰å¯ç”¨çš„APIå®¢æˆ·ç«¯ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå›å¤æ¨¡å¼")
    
    def _set_active_model(self, model_type: str):
        """è®¾ç½®å½“å‰æ´»è·ƒçš„æ¨¡å‹"""
        self.model_type = model_type.lower()
        
        if self.model_type == "claude" and self.claude_client:
            self.current_client = self.claude_client
            self.use_api = True
            print(f"ğŸ¤– ChatAI: åˆ‡æ¢åˆ°Claudeæ¨¡å‹")
        elif self.model_type == "doubao" and self.doubao_client:
            self.current_client = self.doubao_client
            self.use_api = True
            print(f"ğŸ¤– ChatAI: åˆ‡æ¢åˆ°Doubaoæ¨¡å‹")
        else:
            self.current_client = None
            self.use_api = False
            print(f"ğŸ¤– ChatAI: æ¨¡å‹ {model_type} ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå›å¤æ¨¡å¼")
    
    def switch_model(self, model_type: str):
        """åŠ¨æ€åˆ‡æ¢AIæ¨¡å‹"""
        print(f"ğŸ¤– ChatAI: å°è¯•åˆ‡æ¢åˆ° {model_type} æ¨¡å‹")
        self._set_active_model(model_type)
        # æ¸…é™¤ç¼“å­˜ä»¥ç¡®ä¿ä½¿ç”¨æ–°æ¨¡å‹
        self.response_cache.clear()
    
    def get_available_models(self) -> List[str]:
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        available = []
        if self.claude_client:
            available.append("claude")
        if self.doubao_client:
            available.append("doubao")
        available.append("mock")  # æ¨¡æ‹Ÿæ¨¡å¼æ€»æ˜¯å¯ç”¨
        return available
    
    def get_current_model_info(self) -> Dict:
        """è·å–å½“å‰æ¨¡å‹ä¿¡æ¯"""
        return {
            "model_type": self.model_type,
            "use_api": self.use_api,
            "available_models": self.get_available_models(),
            "client_status": {
                "claude": self.claude_client is not None,
                "doubao": self.doubao_client is not None
            }
        }
    
    def get_best_model_for_npc(self, npc_id: str) -> str:
        """æ ¹æ®NPCè·å–æœ€ä½³æ¨¡å‹"""
        return self.config_manager.get_preferred_model_for_npc(npc_id)
    
    def auto_switch_model_for_npc(self, npc_id: str):
        """ä¸ºNPCè‡ªåŠ¨åˆ‡æ¢åˆ°æœ€ä½³æ¨¡å‹"""
        best_model = self.get_best_model_for_npc(npc_id)
        if best_model != self.model_type:
            print(f"ğŸ”„ ä¸ºNPC {npc_id} è‡ªåŠ¨åˆ‡æ¢åˆ° {best_model} æ¨¡å‹")
            self.switch_model(best_model)
    
    async def generate_npc_response(self, npc_id: str, player_message: str, context: Dict = None) -> str:
        """
        ä¸ºNPCç”Ÿæˆå›å¤
        
        Args:
            npc_id: NPCçš„ID
            player_message: ç©å®¶çš„æ¶ˆæ¯
            context: é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚ç©å®¶çŠ¶æ€ã€æ¸¸æˆè¿›åº¦ç­‰ï¼‰
            
        Returns:
            NPCçš„å›å¤æ–‡æœ¬
        """
        
        # è‡ªåŠ¨ä¸ºNPCé€‰æ‹©æœ€ä½³æ¨¡å‹
        self.auto_switch_model_for_npc(npc_id)
        
        # æ·»åŠ ç©å®¶æ¶ˆæ¯åˆ°å¯¹è¯å†å²
        self._add_to_conversation_history(npc_id, "ç©å®¶", player_message)
        
        # ç”ŸæˆåŒ…å«å†å²çš„ç¼“å­˜é”®ï¼ˆè€ƒè™‘æœ€è¿‘3è½®å¯¹è¯å’Œæ¨¡å‹ç±»å‹ï¼‰
        recent_history = self._get_recent_conversation_context(npc_id, 3)
        cache_key = f"{npc_id}:{self.model_type}:{hash(str(recent_history) + player_message)}"
        
        if cache_key in self.response_cache:
            response = self.response_cache[cache_key]
        elif self.use_api and self.current_client:
            try:
                response = await self._generate_api_response(npc_id, player_message, context)
                # ç¼“å­˜å›å¤
                self.response_cache[cache_key] = response
            except Exception as e:
                print(f"ğŸ¤– ChatAI: {self.model_type} APIè°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿæ¨¡å¼: {e}")
                # å›é€€åˆ°æ¨¡æ‹Ÿå›å¤
                response = self._generate_mock_response(npc_id, player_message)
        else:
            response = self._generate_mock_response(npc_id, player_message)
        
        # æ·»åŠ NPCå›å¤åˆ°å¯¹è¯å†å²
        self._add_to_conversation_history(npc_id, self.npc_personalities.get(npc_id, {}).get("name", "NPC"), response)
        
        return response
    
    async def _generate_api_response(self, npc_id: str, player_message: str, context: Dict = None) -> str:
        """ä½¿ç”¨å½“å‰é€‰å®šçš„APIç”Ÿæˆå›å¤"""
        if self.model_type == "claude":
            return await self._generate_claude_response(npc_id, player_message, context)
        elif self.model_type == "doubao":
            return await self._generate_doubao_response(npc_id, player_message, context)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.model_type}")
    
    async def _generate_claude_response(self, npc_id: str, player_message: str, context: Dict = None) -> str:
        """ä½¿ç”¨Claude APIç”Ÿæˆå›å¤"""
        
        npc_info = self.npc_personalities.get(npc_id, {
            "name": "NPC",
            "personality": "å‹å¥½çš„æ‘æ°‘",
            "context": "å°é•‡å±…æ°‘",
            "speaking_style": "å‹å¥½éšå’Œ"
        })
        
        # è·å–å¯¹è¯å†å²
        conversation_history = self._format_conversation_history(npc_id, 5)
        
        # æ„å»ºæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯æ¸¸æˆã€ŠèŒçˆªé’“é±¼ã€‹ä¸­çš„NPCï¼š{npc_info['name']}

**è§’è‰²è®¾å®šï¼š**
- æ€§æ ¼ï¼š{npc_info['personality']}
- èƒŒæ™¯ï¼š{npc_info['context']}
- è¯´è¯é£æ ¼ï¼š{npc_info['speaking_style']}

**é‡è¦æŒ‡ç¤ºï¼š**
1. è¯·å§‹ç»ˆä»¥{npc_info['name']}çš„èº«ä»½å›å¤
2. ä¿æŒè§’è‰²çš„æ€§æ ¼å’Œè¯´è¯é£æ ¼
3. å›å¤è¦ç®€æ´è‡ªç„¶ï¼ŒåƒçœŸæ­£çš„å¯¹è¯
4. ä¸è¦æåŠä½ æ˜¯AIæˆ–æ¸¸æˆè§’è‰²
5. å›å¤é•¿åº¦æ§åˆ¶åœ¨1-2å¥è¯
6. ä½¿ç”¨ä¸­æ–‡å›å¤
7. åŸºäºå¯¹è¯å†å²ä¿æŒè¿è´¯æ€§ï¼Œè®°ä½ä¹‹å‰èŠè¿‡çš„å†…å®¹
8. å¦‚æœç©å®¶æåˆ°ä¹‹å‰çš„è¯é¢˜ï¼Œè¦èƒ½å¤Ÿå›åº”

**å¯¹è¯ä¸Šä¸‹æ–‡ï¼š**
{conversation_history}

**å½“å‰æƒ…å†µï¼š**
ç©å®¶å¯¹ä½ è¯´ï¼š"{player_message}"

è¯·ä»¥{npc_info['name']}çš„èº«ä»½ï¼ŒåŸºäºå¯¹è¯å†å²è‡ªç„¶å›å¤ï¼š"""

        try:
            response = self.claude_client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=150,
                temperature=0.7,
                messages=[
                    {
                        "role": "user", 
                        "content": system_prompt
                    }
                ]
            )
            
            response_text = response.content[0].text.strip()
            
            # æ¸…ç†å›å¤ï¼ˆç§»é™¤å¯èƒ½çš„å¼•å·æˆ–æ ¼å¼ç¬¦å·ï¼‰
            response_text = response_text.strip('"\'`')
            
            return response_text
            
        except Exception as e:
            print(f"ğŸ¤– ChatAI: Claude APIè°ƒç”¨å¼‚å¸¸: {e}")
            raise e
    
    async def _generate_doubao_response(self, npc_id: str, player_message: str, context: Dict = None) -> str:
        """ä½¿ç”¨Doubao APIç”Ÿæˆå›å¤"""
        
        npc_info = self.npc_personalities.get(npc_id, {
            "name": "NPC",
            "personality": "å‹å¥½çš„æ‘æ°‘",
            "context": "å°é•‡å±…æ°‘",
            "speaking_style": "å‹å¥½éšå’Œ"
        })
        
        # è·å–å¯¹è¯å†å²
        conversation_history = self._format_conversation_history(npc_id, 5)
        
        # æ„å»ºæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯æ¸¸æˆã€ŠèŒçˆªé’“é±¼ã€‹ä¸­çš„NPCï¼š{npc_info['name']}

**è§’è‰²è®¾å®šï¼š**
- æ€§æ ¼ï¼š{npc_info['personality']}
- èƒŒæ™¯ï¼š{npc_info['context']}
- è¯´è¯é£æ ¼ï¼š{npc_info['speaking_style']}

**é‡è¦æŒ‡ç¤ºï¼š**
1. è¯·å§‹ç»ˆä»¥{npc_info['name']}çš„èº«ä»½å›å¤
2. ä¿æŒè§’è‰²çš„æ€§æ ¼å’Œè¯´è¯é£æ ¼
3. å›å¤è¦ç®€æ´è‡ªç„¶ï¼ŒåƒçœŸæ­£çš„å¯¹è¯
4. ä¸è¦æåŠä½ æ˜¯AIæˆ–æ¸¸æˆè§’è‰²
5. å›å¤é•¿åº¦æ§åˆ¶åœ¨1-2å¥è¯
6. ä½¿ç”¨ä¸­æ–‡å›å¤
7. åŸºäºå¯¹è¯å†å²ä¿æŒè¿è´¯æ€§ï¼Œè®°ä½ä¹‹å‰èŠè¿‡çš„å†…å®¹
8. å¦‚æœç©å®¶æåˆ°ä¹‹å‰çš„è¯é¢˜ï¼Œè¦èƒ½å¤Ÿå›åº”

**å¯¹è¯ä¸Šä¸‹æ–‡ï¼š**
{conversation_history}

**å½“å‰æƒ…å†µï¼š**
ç©å®¶å¯¹ä½ è¯´ï¼š"{player_message}"

è¯·ä»¥{npc_info['name']}çš„èº«ä»½ï¼ŒåŸºäºå¯¹è¯å†å²è‡ªç„¶å›å¤ï¼š"""

        try:
            response = self.doubao_client.chat.completions.create(
                model="doubao-seed-1-6-250615",
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªæ¸¸æˆä¸­çš„NPCè§’è‰²ï¼Œéœ€è¦æ ¹æ®è§’è‰²è®¾å®šè¿›è¡Œå¯¹è¯ã€‚"
                    },
                    {
                        "role": "user", 
                        "content": system_prompt
                    }
                ],
                max_tokens=150,
                temperature=0.7
            )
            
            response_text = response.choices[0].message.content.strip()
            
            # æ¸…ç†å›å¤ï¼ˆç§»é™¤å¯èƒ½çš„å¼•å·æˆ–æ ¼å¼ç¬¦å·ï¼‰
            response_text = response_text.strip('"\'`')
            
            return response_text
            
        except Exception as e:
            print(f"ğŸ¤– ChatAI: Doubao APIè°ƒç”¨å¼‚å¸¸: {e}")
            raise e
    
    def _generate_mock_response(self, npc_id: str, player_message: str) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿå›å¤"""
        
        # è·å–å¯¹è¯å†å²
        recent_history = self._get_recent_conversation_context(npc_id, 3)
        
        # è·å–è¯¥NPCçš„æ¨¡æ‹Ÿå›å¤åˆ—è¡¨
        npc_responses = self.mock_responses.get(npc_id, [
            "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ã€‚",
            "æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ",
            "ä»Šå¤©å¤©æ°”ä¸é”™å‘¢ï¼",
            "å°é•‡ç”Ÿæ´»å¾ˆå¹³é™ã€‚"
        ])
        
        # æ‰©å±•æ¨¡æ‹Ÿå›å¤ï¼ŒåŒ…å«ä¸Šä¸‹æ–‡ç›¸å…³çš„å›å¤
        contextual_responses = {
            "trader_zhang": {
                "follow_up": [
                    "åˆšæ‰ä½ é—®çš„é‚£ä¸ªï¼Œæˆ‘æƒ³æƒ³...",
                    "è¯´åˆ°è¿™ä¸ªï¼Œæˆ‘è®°å¾—ä½ ä¹‹å‰æè¿‡...",
                    "å¯¹äº†ï¼Œå…³äºä½ åˆšæ‰è¯´çš„äº‹æƒ…...",
                    "ç»§ç»­èŠèŠåˆšæ‰çš„è¯é¢˜å§ã€‚"
                ],
                "topic_responses": {
                    "ç§å­": ["é‚£ä¸ªç§å­ç¡®å®ä¸é”™ï¼Œè¦ä¸è¦å†çœ‹çœ‹å…¶ä»–çš„ï¼Ÿ", "æˆ‘è¿™é‡Œè¿˜æœ‰æ›´å¥½çš„ç§å­å‘¢ï¼"],
                    "ä»·æ ¼": ["ä»·æ ¼éƒ½æ˜¯å…¬é“çš„ï¼Œä½ æ”¾å¿ƒï¼", "è¿™ä¸ªä»·æ ¼åœ¨å¸‚åœºä¸Šç®—ä¾¿å®œçš„äº†ã€‚"],
                    "ç”Ÿæ„": ["ç”Ÿæ„è¿˜è¡Œï¼Œå¤šäºäº†ä½ ä»¬è¿™äº›é¡¾å®¢ï¼", "åšç”Ÿæ„å°±æ˜¯è¦è¯šä¿¡ä¸ºæœ¬ã€‚"]
                }
            },
            "fisherman_li": {
                "follow_up": [
                    "ä½ åˆšæ‰è¯´çš„å¯¹...",
                    "é’“é±¼è¿™äº‹å„¿ï¼Œå¾—æ…¢æ…¢æ¥...",
                    "æˆ‘æƒ³èµ·ä½ ä¹‹å‰é—®è¿‡çš„...",
                    "ç»§ç»­è¯´è¯´é’“é±¼çš„äº‹å§ã€‚"
                ],
                "topic_responses": {
                    "é’“é±¼": ["é’“é±¼ç¡®å®éœ€è¦è€å¿ƒï¼Œä½ è¯•è¿‡äº†å—ï¼Ÿ", "ä»Šå¤©çš„é±¼æ¯”æ˜¨å¤©æ´»è·ƒå¤šäº†ã€‚"],
                    "æŠ€å·§": ["æŠ€å·§è¿™ä¸œè¥¿ï¼Œå¾—å¤šç»ƒä¹ ã€‚", "æˆ‘å¯ä»¥æ•™ä½ ä¸€äº›çªé—¨ã€‚"],
                    "è€å¿ƒ": ["è€å¿ƒæ˜¯é’“é±¼æœ€é‡è¦çš„å“è´¨ã€‚", "æ€¥èºçš„äººé’“ä¸åˆ°å¥½é±¼ã€‚"]
                }
            },
            "farmer_wang": {
                "follow_up": [
                    "ä½ è¯´å¾—æœ‰é“ç†...",
                    "ç§åœ°çš„äº‹å„¿ï¼Œæˆ‘æœ€æœ‰å‘è¨€æƒ...",
                    "åˆšæ‰èŠåˆ°çš„é‚£ä¸ª...",
                    "å†œä¸šè¿™è¡Œå½“ä¸å®¹æ˜“å•Šã€‚"
                ],
                "topic_responses": {
                    "ç§æ¤": ["ç§æ¤è¦çœ‹å¤©æ—¶åœ°åˆ©ã€‚", "è¿™å­£èŠ‚ç§ä»€ä¹ˆéƒ½ä¸é”™ã€‚"],
                    "å¤©æ°”": ["å¤©æ°”ç¡®å®å¾ˆé‡è¦ï¼Œå½±å“æ”¶æˆã€‚", "çœ‹è¿™å¤©è‰²ï¼Œåº”è¯¥è¦ä¸‹é›¨äº†ã€‚"],
                    "ä½œç‰©": ["ä½œç‰©é•¿å¾—æ€ä¹ˆæ ·ï¼Ÿ", "ä»Šå¹´çš„æ”¶æˆåº”è¯¥ä¸é”™ã€‚"]
                }
            }
        }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹è¯å†å²ï¼Œå¦‚æœæœ‰åˆ™è€ƒè™‘ä¸Šä¸‹æ–‡
        message_lower = player_message.lower()
        
        # å¦‚æœæœ‰å¯¹è¯å†å²ï¼Œä¼˜å…ˆä½¿ç”¨ä¸Šä¸‹æ–‡ç›¸å…³å›å¤
        if recent_history and len(recent_history) > 0:
            last_messages = [entry["message"].lower() for entry in recent_history[-3:]]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸å…³è¯é¢˜çš„å»¶ç»­
            if npc_id in contextual_responses:
                npc_context = contextual_responses[npc_id]
                
                # æ£€æŸ¥è¯é¢˜è¿ç»­æ€§
                for topic, responses in npc_context.get("topic_responses", {}).items():
                    if any(topic in msg for msg in last_messages) or topic in message_lower:
                        import random
                        return random.choice(responses)
                
                # ä½¿ç”¨è·Ÿè¿›å›å¤
                if len(recent_history) >= 2:  # å¦‚æœå·²ç»æœ‰ä¸€äº›å¯¹è¯
                    import random
                    follow_up_chance = random.random()
                    if follow_up_chance < 0.3:  # 30%çš„æ¦‚ç‡ä½¿ç”¨è·Ÿè¿›å›å¤
                        return random.choice(npc_context["follow_up"])
        
        # åŸæœ‰çš„å…³é”®è¯åŒ¹é…é€»è¾‘
        if any(word in message_lower for word in ['ä½ å¥½', 'hello', 'å—¨', 'æ—©ä¸Šå¥½', 'æ™šä¸Šå¥½']):
            # å¦‚æœä¹‹å‰å·²ç»æ‰“è¿‡æ‹›å‘¼ï¼Œç”¨ä¸åŒçš„å›å¤
            if recent_history and any("ä½ å¥½" in entry["message"] for entry in recent_history):
                return "æˆ‘ä»¬ä¸æ˜¯åˆšèŠè¿‡å—ï¼Ÿå“ˆå“ˆã€‚"
            greetings = [resp for resp in npc_responses if any(greet in resp for greet in ['ä½ å¥½', 'è§åˆ°ä½ ', 'æœ‹å‹'])]
            if greetings:
                return greetings[0]
        
        elif any(word in message_lower for word in ['é’“é±¼', 'é±¼', 'fishing']) and npc_id == "fisherman_li":
            fishing_responses = [resp for resp in npc_responses if any(word in resp for word in ['é’“é±¼', 'é±¼å„¿', 'è€å¿ƒ'])]
            if fishing_responses:
                return fishing_responses[0]
        
        elif any(word in message_lower for word in ['ç§å­', 'ä¹°', 'å–', 'ç”Ÿæ„']) and npc_id == "trader_zhang":
            trade_responses = [resp for resp in npc_responses if any(word in resp for word in ['ç§å­', 'ç”Ÿæ„', 'è´§', 'ä»·æ ¼'])]
            if trade_responses:
                return trade_responses[0]
        
        elif any(word in message_lower for word in ['å†œä¸š', 'ç§æ¤', 'ä½œç‰©', 'åœŸåœ°']) and npc_id == "farmer_wang":
            farm_responses = [resp for resp in npc_responses if any(word in resp for word in ['ä½œç‰©', 'åœŸåœ°', 'å†œä¸š', 'åº„ç¨¼'])]
            if farm_responses:
                return farm_responses[0]
        
        # é»˜è®¤è¿”å›éšæœºå›å¤
        import random
        return random.choice(npc_responses)
    
    def get_nearby_npc(self, player_pos: tuple, npc_sprites) -> Optional[str]:
        """
        è·å–ç©å®¶é™„è¿‘çš„NPC
        
        Args:
            player_pos: ç©å®¶ä½ç½® (x, y)
            npc_sprites: NPCç²¾çµç»„
            
        Returns:
            é™„è¿‘NPCçš„IDï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        interaction_distance = 150  # å¢å¤§èŠå¤©äº¤äº’è·ç¦»
        
        print(f"[ChatAI] æ£€æŸ¥é™„è¿‘NPCï¼Œç©å®¶ä½ç½®: {player_pos}")
        
        for npc in npc_sprites:
            npc_pos = npc.rect.center
            distance = ((player_pos[0] - npc_pos[0]) ** 2 + 
                       (player_pos[1] - npc_pos[1]) ** 2) ** 0.5
            
            print(f"[ChatAI] NPC {npc.npc_id} ä½ç½®: {npc_pos}, è·ç¦»: {distance:.1f}")
            
            if distance <= interaction_distance:
                print(f"[ChatAI] æ‰¾åˆ°é™„è¿‘çš„NPC: {npc.npc_id}")
                return npc.npc_id
        
        print("[ChatAI] æ²¡æœ‰æ‰¾åˆ°é™„è¿‘çš„NPC")
        return None
    
    def add_context_from_game_state(self, player, level) -> Dict:
        """
        ä»æ¸¸æˆçŠ¶æ€ä¸­æå–ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Args:
            player: ç©å®¶å¯¹è±¡
            level: å…³å¡å¯¹è±¡
            
        Returns:
            ä¸Šä¸‹æ–‡å­—å…¸
        """
        context = {
            "player_money": getattr(player, 'money', 0),
            "player_level": getattr(player, 'level', 1),
            "current_time": datetime.now().strftime("%H:%M"),
            "weather": "æ™´æœ—" if not getattr(level, 'raining', False) else "ä¸‹é›¨"
        }
        
        # æ·»åŠ ç©å®¶åº“å­˜ä¿¡æ¯
        if hasattr(player, 'item_inventory'):
            context["player_items"] = dict(player.item_inventory)
        
        # æ·»åŠ é’“é±¼ç»Ÿè®¡
        if hasattr(player, 'fishing_contest_stats'):
            context["fishing_stats"] = dict(player.fishing_contest_stats)
        
        return context
    
    def _add_to_conversation_history(self, npc_id: str, speaker: str, message: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²"""
        if npc_id not in self.conversation_history:
            self.conversation_history[npc_id] = []
        
        self.conversation_history[npc_id].append({
            "speaker": speaker,
            "message": message,
            "timestamp": datetime.now().isoformat()
        })
        
        # é™åˆ¶å†å²é•¿åº¦
        if len(self.conversation_history[npc_id]) > self.max_history_length * 2:  # *2å› ä¸ºåŒ…å«ç©å®¶å’ŒNPCçš„æ¶ˆæ¯
            self.conversation_history[npc_id] = self.conversation_history[npc_id][-self.max_history_length * 2:]
        
        print(f"[ChatAI] æ·»åŠ å¯¹è¯å†å² {npc_id}: {speaker}: {message}")
    
    def _get_recent_conversation_context(self, npc_id: str, num_turns: int = 3) -> List[Dict]:
        """è·å–æœ€è¿‘çš„å¯¹è¯ä¸Šä¸‹æ–‡"""
        if npc_id not in self.conversation_history:
            return []
        
        # è·å–æœ€è¿‘çš„å¯¹è¯è®°å½•
        recent_messages = self.conversation_history[npc_id][-num_turns * 2:]  # *2å› ä¸ºåŒ…å«ç©å®¶å’ŒNPC
        return recent_messages
    
    def _format_conversation_history(self, npc_id: str, num_turns: int = 5) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²ä¸ºæ–‡æœ¬"""
        recent_history = self._get_recent_conversation_context(npc_id, num_turns)
        
        if not recent_history:
            return "è¿™æ˜¯ä½ ä»¬çš„ç¬¬ä¸€æ¬¡å¯¹è¯ã€‚"
        
        formatted_history = "æœ€è¿‘çš„å¯¹è¯å†å²:\n"
        for entry in recent_history:
            formatted_history += f"{entry['speaker']}: {entry['message']}\n"
        
        return formatted_history
    
    def clear_conversation_history(self, npc_id: str = None):
        """æ¸…é™¤å¯¹è¯å†å²"""
        if npc_id:
            if npc_id in self.conversation_history:
                del self.conversation_history[npc_id]
                print(f"[ChatAI] æ¸…é™¤{npc_id}çš„å¯¹è¯å†å²")
        else:
            self.conversation_history.clear()
            print("[ChatAI] æ¸…é™¤æ‰€æœ‰å¯¹è¯å†å²")
    
    def get_conversation_summary(self, npc_id: str) -> Dict:
        """è·å–å¯¹è¯æ‘˜è¦"""
        if npc_id not in self.conversation_history:
            return {"total_messages": 0, "last_interaction": None}
        
        history = self.conversation_history[npc_id]
        return {
            "total_messages": len(history),
            "last_interaction": history[-1]["timestamp"] if history else None,
            "recent_topics": [msg["message"][:50] + "..." if len(msg["message"]) > 50 else msg["message"] 
                            for msg in history[-3:]]
        }

# å…¨å±€èŠå¤©AIå®ä¾‹
_chat_ai_instance = None

def get_chat_ai():
    """è·å–èŠå¤©AIå•ä¾‹"""
    global _chat_ai_instance
    if _chat_ai_instance is None:
        _chat_ai_instance = ChatAI()
    return _chat_ai_instance